{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy \n",
    "data = scipy.io.loadmat('Indian_pines_corrected.mat')  # imported data as dictionary\n",
    "inp_table=data.pop('indian_pines_corrected') # extract specific key value pair\n",
    "inp_table=inp_table.reshape(-1,200)  # flatning input data as 1D \n",
    "datao=scipy.io.loadmat('Indian_pines_gt.mat')  # imported ground truth as dictionary\n",
    "gt=datao['indian_pines_gt']   # extract specific key value pair\n",
    "gt=gt.reshape(-1,1)   # flatning ground truth data as 1D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices=numpy.where(gt==0)[0]  # finding all indices with ground truth value 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_gt=numpy.delete(gt,indices,0)  # Deleting entries with 0 as the output class from ground truth\n",
    "updated_inp_table=numpy.delete(inp_table,indices,0) # Deleting entries with 0 as the output class from input data\n",
    "updated_inp_table=updated_inp_table.astype(float) # Updating data type of input data as float\n",
    "row,col=updated_inp_table.shape  # Storing rows and columns in input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_gt=numpy.zeros((row,16))  # Defining zeros numpy matrix (10249, 16)\n",
    "for i in range(row):\n",
    "    onehot_gt[i][updated_gt[i]-1]=1   # making 1 only at the class of the input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(updated_inp_table,onehot_gt,test_size=0.5,random_state=0)  # Spliting train and test data\n",
    "\n",
    "\n",
    "for i in range(x_train.shape[0]):\n",
    "    x_train[i,:]=x_train[i,:]/numpy.max(x_train[i,:])  # Scaling input train data\n",
    "\n",
    "\n",
    "for i in range(x_test.shape[0]):\n",
    "    x_test[i,:]=x_test[i,:]/numpy.max(x_test[i,:])  # Scaling input test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: 0.0\n",
      "Squared ERROR  15.0\n",
      "Cost: -2.5044098901119347\n",
      "Squared ERROR  11.373305234383606\n",
      "Cost: -2.9779960764009967\n",
      "Squared ERROR  10.85579172215176\n",
      "Cost: -3.3121371739003282\n",
      "Squared ERROR  10.50200263527783\n",
      "Cost: -3.575653803142197\n",
      "Squared ERROR  10.227318185567578\n",
      "Cost: -3.795578856589495\n",
      "Squared ERROR  10.002192288034939\n",
      "Cost: -3.985171367685795\n",
      "Squared ERROR  9.814532136354025\n",
      "Cost: -4.15200188926278\n",
      "Squared ERROR  9.656230775618415\n",
      "Cost: -4.30104446659424\n",
      "Squared ERROR  9.5203504492246\n",
      "Cost: -4.435847582295638\n",
      "Squared ERROR  9.401470950763784\n",
      "Cost: -4.559039102081398\n",
      "Squared ERROR  9.295678635385615\n",
      "Cost: -4.672606788965142\n",
      "Squared ERROR  9.200207180856138\n",
      "Cost: -4.77808031028288\n",
      "Squared ERROR  9.113080060549539\n",
      "Cost: -4.876655926552802\n",
      "Squared ERROR  9.032851405537619\n",
      "Cost: -4.969283586451934\n",
      "Squared ERROR  8.958434879173394\n",
      "Cost: -5.056728540140222\n",
      "Squared ERROR  8.888992986147803\n",
      "Cost: -5.139615485770478\n",
      "Squared ERROR  8.8238649256227\n",
      "Cost: -5.218460631562391\n",
      "Squared ERROR  8.762518659899557\n",
      "Cost: -5.293695305891781\n",
      "Squared ERROR  8.704518316463023\n",
      "Cost: -5.365683583091267\n",
      "Squared ERROR  8.649501469274371\n",
      "Cost: -5.434735617078578\n",
      "Squared ERROR  8.597162921596079\n",
      "Cost: -5.50111785611426\n",
      "Squared ERROR  8.547242864484991\n",
      "Cost: -5.565060962121392\n",
      "Squared ERROR  8.499518046869845\n",
      "Cost: -5.62676601963956\n",
      "Squared ERROR  8.45379506384938\n",
      "Cost: -5.686409455248001\n",
      "Squared ERROR  8.409905165964107\n",
      "Cost: -5.744146973794075\n",
      "Squared ERROR  8.367700182005763\n",
      "Cost: -5.800116736997604\n",
      "Squared ERROR  8.32704927192027\n",
      "Cost: -5.854441952370771\n",
      "Squared ERROR  8.287836308882396\n",
      "Cost: -5.907232998808639\n",
      "Squared ERROR  8.249957745552502\n",
      "Cost: -5.9585891848741195\n",
      "Squared ERROR  8.21332085811216\n",
      "Cost: -6.008600213448815\n",
      "Squared ERROR  8.177842288752608\n",
      "Cost: -6.057347409784731\n",
      "Squared ERROR  8.143446826604485\n",
      "Cost: -6.104904757492488\n",
      "Squared ERROR  8.110066381091267\n",
      "Cost: -6.15133977752515\n",
      "Squared ERROR  8.077639111978634\n",
      "Cost: -6.19671427797047\n",
      "Squared ERROR  8.04610868806514\n",
      "Cost: -6.241084996876843\n",
      "Squared ERROR  8.015423652255876\n",
      "Cost: -6.284504155997173\n",
      "Squared ERROR  7.985536875193748\n",
      "Cost: -6.327019939935452\n",
      "Squared ERROR  7.956405083051212\n",
      "Cost: -6.3686769125010105\n",
      "Squared ERROR  7.927988447764397\n",
      "Cost: -6.409516379947878\n",
      "Squared ERROR  7.900250230105518\n",
      "Cost: -6.449576709076705\n",
      "Squared ERROR  7.873156467671835\n",
      "Cost: -6.488893606810122\n",
      "Squared ERROR  7.846675701219428\n",
      "Cost: -6.527500366747341\n",
      "Squared ERROR  7.820778733861063\n",
      "Cost: -6.56542808730519\n",
      "Squared ERROR  7.795438418535252\n",
      "Cost: -6.602705865318145\n",
      "Squared ERROR  7.770629469880163\n",
      "Cost: -6.639360968366335\n",
      "Squared ERROR  7.7463282972445064\n",
      "Cost: -6.6754189886022015\n",
      "Squared ERROR  7.72251285606239\n",
      "Cost: -6.710903980433235\n",
      "Squared ERROR  7.699162515230751\n",
      "Cost: -6.745838584073981\n",
      "Squared ERROR  7.676257938471619\n",
      "Cost: -6.780244136692504\n",
      "Squared ERROR  7.653780977949481\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "weights=numpy.zeros((200,16))    # Defining weight matrix (200,16) all zeros entry\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "for i in range(50000):\n",
    "    y_cal=numpy.dot(x_train,weights)  # product of weights and input data\n",
    "    \n",
    "    expo_val=numpy.exp(y_cal)   # finding exponential of each value\n",
    "                            \n",
    "    train_row,train_col=y_train.shape  # storing rows and columns of data\n",
    "\n",
    "    \n",
    "    cost=(1/train_row)*(numpy.sum(-y_train*numpy.log(expo_val))) # finding cost \n",
    "   \n",
    "    norm_expo_val = normalize(expo_val, axis=1, norm='l1')  # normalizing the exponantial values this will give probalility \n",
    "    \n",
    "    if(i%1000==0):\n",
    "        print(\"Cost: \"+str(cost))   # printing cost after every 1000 iterations\n",
    "        print(\"Squared ERROR  \"+ str( (numpy.sum(numpy.square(y_train-norm_expo_val))/train_row*train_col)))  # printing squared error after  every 1000 iterations\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "    M=y_train-norm_expo_val  # defining M (10249, 16) matrix\n",
    "\n",
    "    M=M.T\n",
    "    grad=(numpy.dot(M,x_train))+(0.1*weights.T) #  finding gradient \n",
    "    grad=grad/train_row     \n",
    "\n",
    "    weights=weights+(0.1*grad.T) # updating weights\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Test Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 64.62439024390244\n"
     ]
    }
   ],
   "source": [
    "y_cal_test=numpy.dot(x_test,weights)    \n",
    "expo_val_test=numpy.exp(y_cal_test)\n",
    "norm_expo_val_test = normalize(expo_val_test, axis=1, norm='l1')\n",
    "\n",
    "cou=0    # Initilize count to zeoo                                           \n",
    "\n",
    "p=numpy.argmax(norm_expo_val_test,axis=1)\n",
    "q=numpy.argmax(y_test,axis=1)\n",
    "for i in range(x_test.shape[0]):\n",
    "    if(p[i]==q[i]):\n",
    "        cou+=1       # increse count for each correct classification\n",
    "\n",
    "print(\"Test Accuracy: \"+str(100*cou/x_test.shape[0])) \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
